{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "01-unit-tests.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1XUlgf3fPmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "fa98341e-04ab-444a-c2ce-ab04b72f507e"
      },
      "source": [
        "pip install tensorflow==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 31kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl\u001b[0m\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 30.6MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (47.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=61d450d4f11f8b2a55aacd1a28a98cf3c09ced955670629ba05d6e5cf0e9e30a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8RRSFO2e196",
        "colab_type": "text"
      },
      "source": [
        "# Unit tests con TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPjMijye198",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e25a7d7d-224a-43ed-a01a-cc886ae21d1c"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlnDx3JTe1-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session()\n",
        "!mkdir datasets\n",
        "!mkdir datasets//MNIST_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM0eU0Xue1-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"datasets/MNIST_data\"\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_xdata, train_labels), (test_xdata, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPjkYQzce1-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_xdata = train_xdata / 255.0 # Para que queden la imagenes entre 0 y 1\n",
        "test_xdata = test_xdata / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8-TXGzBe1-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "learning_rate = 0.005\n",
        "evaluation_size = 100\n",
        "image_width = train_xdata[0].shape[0]\n",
        "image_height = train_xdata[0].shape[1]\n",
        "target_size = max(train_labels)+1\n",
        "num_channels = 1\n",
        "generations = 100\n",
        "eval_every = 5\n",
        "conv1_features = 25\n",
        "conv2_features = 50\n",
        "max_pool_size1 = 2\n",
        "max_pool_size2 = 2\n",
        "fully_connected_size1 = 100\n",
        "dropout_prob = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uohjpCJe1-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
        "x_input = tf.placeholder(tf.float32, shape = x_input_shape)\n",
        "y_target = tf.placeholder(tf.int32, shape = (batch_size))\n",
        "\n",
        "eval_input_shape = (evaluation_size, image_width, image_height, num_channels)\n",
        "eval_input = tf.placeholder(tf.float32, shape = eval_input_shape)\n",
        "eval_target = tf.placeholder(tf.int32, shape = (evaluation_size))\n",
        "\n",
        "dropout = tf.placeholder(tf.float32, shape=())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6AI-oRke1-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1_weight = tf.Variable(tf.truncated_normal([4,4,num_channels, conv1_features],\n",
        "                                              stddev=0.1, dtype=tf.float32))\n",
        "conv1_bias = tf.Variable(tf.zeros([conv1_features], dtype = tf.float32))\n",
        "\n",
        "conv2_weight = tf.Variable(tf.truncated_normal([4,4,conv1_features, conv2_features],\n",
        "                                              stddev=0.1, dtype=tf.float32))\n",
        "conv2_bias = tf.Variable(tf.zeros([conv2_features], dtype = tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRedJ9dTe1-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_width = image_width//(max_pool_size1*max_pool_size2)\n",
        "result_height = image_height//(max_pool_size1*max_pool_size2)\n",
        "full1_input_size = result_width*result_height*conv2_features\n",
        "\n",
        "full1_weight = tf.Variable(tf.truncated_normal([full1_input_size, fully_connected_size1],\n",
        "                                               stddev=0.1, dtype=tf.float32))\n",
        "full1_bias = tf.Variable(tf.truncated_normal([fully_connected_size1], stddev=0.1, dtype=tf.float32))\n",
        "\n",
        "full2_weight = tf.Variable(tf.truncated_normal([fully_connected_size1, target_size],\n",
        "                                               stddev=0.1, dtype=tf.float32))\n",
        "full2_bias = tf.Variable(tf.truncated_normal([target_size], stddev=0.1, dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paVOH_7se1_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_conv_net(input_data):\n",
        "    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
        "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
        "    max_pool1 = tf.nn.max_pool(relu1, ksize = [1,max_pool_size1, max_pool_size1,1],\n",
        "                              strides = [1,max_pool_size1, max_pool_size1, 1], padding = \"SAME\")\n",
        "    \n",
        "    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
        "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
        "    max_pool2 = tf.nn.max_pool(relu2, ksize = [1,max_pool_size2, max_pool_size2,1],\n",
        "                              strides = [1,max_pool_size2, max_pool_size2, 1], padding = \"SAME\")\n",
        "    \n",
        "    final_conv_shape = max_pool2.get_shape().as_list()\n",
        "    final_shape = final_conv_shape[1]*final_conv_shape[2]*final_conv_shape[3]\n",
        "    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n",
        "    \n",
        "    full_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
        "\n",
        "    full_connected2 = tf.add(tf.matmul(full_connected1, full2_weight), full2_bias)\n",
        "\n",
        "    final_model_output = tf.nn.dropout(full_connected2, dropout)\n",
        "    return final_model_output\n",
        "\n",
        "\n",
        "model_output = my_conv_net(x_input)\n",
        "test_model_output = my_conv_net(eval_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s82b69qe1_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-AJPklce1_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = tf.nn.softmax(model_output)\n",
        "test_prediction = tf.nn.softmax(test_model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if9hPDh1e1_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(logits, targets):\n",
        "    batch_predictions = np.argmax(logits, axis=1)\n",
        "    num_correct = np.sum(np.equal(batch_predictions, targets))\n",
        "    return 100.0*num_correct/batch_predictions.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_kWcAgke1_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_optim = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
        "train_step = my_optim.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxMqrr1ye1_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "session.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQgQH6rce1_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DropOutTest(tf.test.TestCase):\n",
        "    def dropout_greater_than(self):\n",
        "        with self.test_session():\n",
        "            self.assertGreater(dropout.eval(), 0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWHQnnBLe1_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AccuracyTest(tf.test.TestCase):\n",
        "    def accuracy_exact_test(self):\n",
        "        with self.test_session():\n",
        "            test_preds = [[0.9, 0.1], [0.01,0.99]]\n",
        "            test_targets = [0,1]\n",
        "            test_acc = get_accuracy(test_preds, test_targets)\n",
        "            self.assertEqual(test_acc.eval(), 100.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edvCwKOLe1_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ShapeTest(tf.test.TestCase):\n",
        "    def output_shape_test(self):\n",
        "        with self.test_session():\n",
        "            numpy_array = np.zeros([batch_size, target_size])\n",
        "            self.assertShapeEqual(numpy_array, model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUs3AKVe2AD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(argv):\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    \n",
        "    for i in range(generations):\n",
        "        rand_idx = np.random.choice(len(train_xdata), size = batch_size)\n",
        "        rand_x = train_xdata[rand_idx]\n",
        "        rand_x = np.expand_dims(rand_x, 3)\n",
        "        rand_y = train_labels[rand_idx]\n",
        "        train_dict = {x_input:rand_x, y_target:rand_y, dropout: dropout_prob}\n",
        "        \n",
        "        session.run(train_step, feed_dict=train_dict)\n",
        "        temp_train_loss, temp_train_preds = session.run([loss, prediction], feed_dict=train_dict)\n",
        "        temp_train_acc = get_accuracy(temp_train_preds, rand_y)\n",
        "        \n",
        "        if (i+1) & eval_every == 0:\n",
        "            eval_idx = np.random.choice(len(test_xdata), size = evaluation_size)\n",
        "            eval_x = test_xdata[eval_idx]\n",
        "            eval_x = np.expand_dims(eval_x, 3)\n",
        "            eval_y = test_labels[eval_idx]\n",
        "            test_dict = {eval_input:eval_x, eval_target:eval_y, dropout: 1.0}\n",
        "            \n",
        "            test_preds = session.run(test_prediction, feed_dict=test_dict)\n",
        "            temp_test_acc = get_accuracy(test_preds, eval_y)\n",
        "            \n",
        "            train_loss.append(temp_train_loss)\n",
        "            train_acc.append(temp_train_acc)\n",
        "            test_acc.append(temp_test_acc)\n",
        "            \n",
        "            acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
        "            acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
        "            print(\"Step: {}, Train loss {:.2f}, Train Acc: {:.2f}, Test Acc: {:.2f}\".format(*acc_and_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "t4V_6eNke2AI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "5670d963-1ead-4e1b-b1d3-5b59408798a2"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    cmd_args = sys.argv\n",
        "    if len(cmd_args)>1 and cmd_args[1] == \"test\":\n",
        "        tf.test.main(argv=cmd_args[1:])\n",
        "    else:\n",
        "        tf.app.run(main = None, argv=cmd_args)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 2, Train loss 2337.76, Train Acc: 12.00, Test Acc: 12.00\n",
            "Step: 8, Train loss 2.94, Train Acc: 18.00, Test Acc: 10.00\n",
            "Step: 10, Train loss 3.20, Train Acc: 8.00, Test Acc: 15.00\n",
            "Step: 16, Train loss 2.33, Train Acc: 15.00, Test Acc: 9.00\n",
            "Step: 18, Train loss 2.31, Train Acc: 14.00, Test Acc: 14.00\n",
            "Step: 24, Train loss 2.31, Train Acc: 13.00, Test Acc: 9.00\n",
            "Step: 26, Train loss 2.33, Train Acc: 5.00, Test Acc: 14.00\n",
            "Step: 32, Train loss 2.30, Train Acc: 15.00, Test Acc: 4.00\n",
            "Step: 34, Train loss 2.31, Train Acc: 12.00, Test Acc: 6.00\n",
            "Step: 40, Train loss 2.30, Train Acc: 9.00, Test Acc: 6.00\n",
            "Step: 42, Train loss 2.31, Train Acc: 6.00, Test Acc: 13.00\n",
            "Step: 48, Train loss 2.31, Train Acc: 15.00, Test Acc: 9.00\n",
            "Step: 50, Train loss 2.31, Train Acc: 6.00, Test Acc: 5.00\n",
            "Step: 56, Train loss 2.31, Train Acc: 9.00, Test Acc: 9.00\n",
            "Step: 58, Train loss 2.31, Train Acc: 6.00, Test Acc: 12.00\n",
            "Step: 64, Train loss 2.30, Train Acc: 7.00, Test Acc: 10.00\n",
            "Step: 66, Train loss 2.29, Train Acc: 9.00, Test Acc: 10.00\n",
            "Step: 72, Train loss 2.30, Train Acc: 8.00, Test Acc: 10.00\n",
            "Step: 74, Train loss 2.29, Train Acc: 10.00, Test Acc: 8.00\n",
            "Step: 80, Train loss 2.30, Train Acc: 7.00, Test Acc: 10.00\n",
            "Step: 82, Train loss 2.29, Train Acc: 12.00, Test Acc: 8.00\n",
            "Step: 88, Train loss 2.30, Train Acc: 13.00, Test Acc: 10.00\n",
            "Step: 90, Train loss 2.29, Train Acc: 12.00, Test Acc: 8.00\n",
            "Step: 96, Train loss 2.29, Train Acc: 12.00, Test Acc: 11.00\n",
            "Step: 98, Train loss 2.30, Train Acc: 10.00, Test Acc: 13.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Iod-7we2AO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}