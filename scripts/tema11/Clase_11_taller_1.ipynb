{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase 11: taller-1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyPnefTfWobBPZweSVcGOOe3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INFINITY-RUBER/Curso_Deep_Learning_Con_TernsorFlow_Machine-Learning_e_IA-/blob/master/scripts/tema11/Clase_11_taller_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n99GZedJAb4",
        "colab_type": "text"
      },
      "source": [
        "## 1. Divide el data frame en conjunto de entrenamiento y test para aplicar diversas técnicas de las aprendidas en el curso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4XmPhphJKlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN8DptPaI374",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRHUjHg7JIdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session()\n",
        "csv_file = 'original.csv'\n",
        "\n",
        "scores = []\n",
        "\n",
        "with open(csv_file,'rt') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter =',')\n",
        "    for row in reader:\n",
        "      scores.append(([x.replace('Female', '0').replace('Male', '1') for x in row[0:5]]))\n",
        "\n",
        "csv_scores = scores\n",
        "scores_header = csv_scores[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw0KSEcxMGQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_scores[0:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECkY7ZrlMPha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores_header"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Ouw-zxMuLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_vals = np.array([int(x[4]) for x in csv_scores[1:] if len(x)>=1])\n",
        "x_vals = np.array([list(map(int, x[0:4])) for x in csv_scores[1:] if len(x)>=1])\n",
        "\n",
        "seed = 2020\n",
        "tf.set_random_seed(seed)\n",
        "np.random.seed(seed)\n",
        "batch_size = 20\n",
        "\n",
        "train_idx = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
        "test_idx = np.array(list(set(range(len(x_vals)))-set(train_idx)))\n",
        "\n",
        "x_vals_train = x_vals[train_idx]\n",
        "x_vals_test = x_vals[test_idx]\n",
        "y_vals_train = y_vals[train_idx]\n",
        "y_vals_test = y_vals[test_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOmPncJeM-Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_vals_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAhzb00wNO-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_cols(m, col_min = np.array([None]), col_max = np.array([None])):\n",
        "  if not col_min[0]:\n",
        "      col_min = m.min(axis=0)\n",
        "  if not col_max[0]:\n",
        "      col_max = m.max(axis=0)\n",
        "  return(m-col_min)/(col_max-col_min), col_min, col_max\n",
        "\n",
        "x_vals_train, train_min, train_max = np.nan_to_num(normalize_cols(x_vals_train))\n",
        "x_vals_test,_,_ = np.nan_to_num(normalize_cols(x_vals_test, train_min, train_max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2r8EZZpNmS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_vals_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxrJZ2prOFU3",
        "colab_type": "text"
      },
      "source": [
        "## 2. Utiliza las diferentes técnicas vistas durante el curso para predecir el Spending Score del cliente en base al resto de columnas del data frame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo-6DM4-OtD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weight(shape, st_dev):\n",
        "  weight = tf.Variable(tf.random_normal(shape = shape, stddev=st_dev))\n",
        "  return weight\n",
        "\n",
        "def init_bias(shape, st_dev):\n",
        "  bias = tf.Variable(tf.random_normal(shape = shape, stddev=st_dev))\n",
        "  return bias\n",
        "\n",
        "x_data = tf.placeholder(shape=[None, 4], dtype = tf.float32)\n",
        "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
        "\n",
        "def full_connected(input_layer, weights, biases):\n",
        "  layer = tf.add(tf.matmul(input_layer, weights), biases)\n",
        "  return(layer)\n",
        "\n",
        "w1 = init_weight(shape=[4,25], st_dev=10.0)\n",
        "b1 = init_bias(shape=[25], st_dev=10.0)\n",
        "layer1 = full_connected(x_data, w1, b1)\n",
        "\n",
        "w2 = init_weight(shape=[25,10], st_dev=10.0)\n",
        "b2 = init_bias(shape=[10], st_dev=10.0)\n",
        "layer2 = full_connected(layer1, w2, b2)\n",
        "\n",
        "w3 = init_weight(shape=[10,3], st_dev=10.0)\n",
        "b3 = init_bias(shape=[3], st_dev=10.0)\n",
        "layer3 = full_connected(layer2, w3, b3)\n",
        "\n",
        "w4 = init_weight(shape=[3,1], st_dev=10.0)\n",
        "b4 = init_bias(shape=[1], st_dev=10.0)\n",
        "layer4 = full_connected(layer3, w4, b4)\n",
        "\n",
        "oss_vects = []\n",
        "\n",
        "test_loss = []\n",
        "\n",
        "for i in range(300):\n",
        "  rand_idx = np.random.choice(len(x_vals_train), size = batch_size)\n",
        "  rand_x = x_vals_train[rand_idx]\n",
        "  rand_y = np.transpose([y_vals_train[rand_idx]])  \n",
        "\n",
        "  session.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y}) \n",
        "  temp_loss = session.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
        "  loss_vects.append(temp_loss)\n",
        "  \n",
        "\n",
        "  test_temp_loss = session.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
        "  test_loss.append(test_temp_loss)  \n",
        "\n",
        "  if(i+1)%25==0:\n",
        "\n",
        "      print(\"Paso #\"+str(i+1)+\", Loss = \"+str(temp_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT9Lslkep_1u",
        "colab_type": "text"
      },
      "source": [
        "## 3. Aplica la validación cruzada para comprobar que el conjunto de test se comporta bien y que tu algoritmo hace una buena predicción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vTnejEE2FZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels = targets))\n",
        "train_step = tf.train.GradientDescentOptimizer(0.025).minimize(loss)\n",
        "prediction = tf.argmax(model_output,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp00RROt4uhY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}