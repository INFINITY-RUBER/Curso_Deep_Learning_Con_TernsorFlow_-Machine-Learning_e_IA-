{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "04-stylenet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INFINITY-RUBER/Curso_Deep_Learning_Con_TernsorFlow_Machine-Learning_e_IA-/blob/master/scripts/tema09/04-stylenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sHuHDL0KTlg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "e27da89e-8ff2-47f4-9570-8aa703468bfe"
      },
      "source": [
        "!wget http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-13 00:57:24--  http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Resolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat [following]\n",
            "--2020-06-13 00:57:24--  https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576042600 (549M)\n",
            "Saving to: ‘imagenet-vgg-verydeep-19.mat’\n",
            "\n",
            "imagenet-vgg-veryde 100%[===================>] 549.36M  34.4MB/s    in 17s     \n",
            "\n",
            "2020-06-13 00:57:41 (32.7 MB/s) - ‘imagenet-vgg-verydeep-19.mat’ saved [576042600/576042600]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWvOGvX6K9gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install tensorflow==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIL6PIxWKPKn",
        "colab_type": "text"
      },
      "source": [
        "# Stylenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJfom7C1KPKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "from operator import mul\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkC4svRQLEye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03946268-4eae-4720-9a24-de841a911811"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C73uBvFsKPKy",
        "colab_type": "text"
      },
      "source": [
        "Ficheros de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJK40yelKPK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ops.reset_default_graph()\n",
        "original_image_file = \"original_image.jpg\"\n",
        "style_image_file = \"style_image.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN3A5frpKPK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_path = \"imagenet-vgg-verydeep-19.mat\"\n",
        "original_image_weight = 5.0\n",
        "style_image_weight = 500.0\n",
        "regularization_weight = 100\n",
        "learning_rate = 10\n",
        "generations = 100\n",
        "output_generations = 10\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTNzY3IKPLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image = imageio.imread(original_image_file)\n",
        "style_image = imageio.imread(style_image_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWLpgIGxKPLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_shape = original_image.shape\n",
        "style_image = resize(style_image, target_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlgMF7IfKPLT",
        "colab_type": "text"
      },
      "source": [
        "Redes neuronales del paper VGG19 disponible en [Arxiv.org](https://arxiv.org/pdf/1508.06576.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rZT3ZtwKPLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_layers = ['conv1_1', 'relu1_1',\n",
        "              'conv1_2', 'relu1_2', 'pool1',\n",
        "              'conv2_1', 'relu2_1',\n",
        "              'conv2_2', 'relu2_2', 'pool2',\n",
        "              'conv3_1', 'relu3_1',\n",
        "              'conv3_2', 'relu3_2',\n",
        "              'conv3_3', 'relu3_3',\n",
        "              'conv3_4', 'relu3_4', 'pool3',\n",
        "              'conv4_1', 'relu4_1',\n",
        "              'conv4_2', 'relu4_2',\n",
        "              'conv4_3', 'relu4_3',\n",
        "              'conv4_4', 'relu4_4', 'pool4',\n",
        "              'conv5_1', 'relu5_1',\n",
        "              'conv5_2', 'relu5_2',\n",
        "              'conv5_3', 'relu5_3',\n",
        "              'conv5_4', 'relu5_4']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-z6gjzHKPLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_net_info(path_to_mat_file):\n",
        "    vgg_data = scipy.io.loadmat(path_to_mat_file)\n",
        "    normalization_matrix = vgg_data[\"normalization\"][0][0][0]\n",
        "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
        "    network_weights = vgg_data['layers'][0]\n",
        "    return mat_mean, network_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEUAfZVRKPLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_network(network_weights, init_image):\n",
        "    network = {}\n",
        "    image = init_image\n",
        "\n",
        "    for i, layer in enumerate(vgg_layers):\n",
        "        if layer[0] == 'c': #convolución\n",
        "            weights, bias = network_weights[i][0][0][0][0]\n",
        "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
        "            bias = bias.reshape(-1)\n",
        "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
        "            image = tf.nn.bias_add(conv_layer, bias)\n",
        "        elif layer[0] == 'r': #relu\n",
        "            image = tf.nn.relu(image)\n",
        "        else:  #max pooling\n",
        "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
        "        network[layer] = image\n",
        "    return network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HInB1SJxKPLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_layers = ['relu4_2', 'relu5_2']\n",
        "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3xwaapKPLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get network parameters\n",
        "normalization_mean, network_weights = extract_net_info(vgg_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqDKjZwFKPL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape = (1,) + original_image.shape\n",
        "style_shape = (1,) + style_image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz_y4RkCKPL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_features = {}\n",
        "style_features = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a92d2nibKPMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2a25ae7a-ee68-45bf-87dc-23d78b019c5e"
      },
      "source": [
        "style_weights = {l: 1./(len(style_layers)) for l in style_layers}\n",
        "style_weights"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'relu1_1': 0.2,\n",
              " 'relu2_1': 0.2,\n",
              " 'relu3_1': 0.2,\n",
              " 'relu4_1': 0.2,\n",
              " 'relu5_1': 0.2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP_BL93VKPMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_original = tf.Graph()\n",
        "with g_original.as_default(), tf.Session() as session1:\n",
        "    image = tf.placeholder(\"float\", shape=shape)\n",
        "    vgg_net = vgg_network(network_weights, image)\n",
        "    original_minus_mean = original_image - normalization_mean\n",
        "    original_norm = np.array([original_minus_mean])\n",
        "    for layer in original_layers:\n",
        "        original_features[layer] = vgg_net[layer].eval(feed_dict={image:original_norm})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQlbcW4OKPMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_style = tf.Graph()\n",
        "with g_style.as_default(), tf.Session() as session2:\n",
        "    image = tf.placeholder(\"float\", shape=style_shape)\n",
        "    vgg_net = vgg_network(network_weights, image)\n",
        "    style_minus_mean = style_image - normalization_mean\n",
        "    style_norm = np.array([style_minus_mean])\n",
        "    for layer in style_layers:\n",
        "        features = vgg_net[layer].eval(feed_dict={image:style_norm})\n",
        "        features = np.reshape(features, (-1, features.shape[3]))\n",
        "        gram = np.matmul(features.T, features)/features.size\n",
        "        style_features[layer] = gram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTW3srAEKPMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "53a0db1e-554e-4ba7-8f33-4149b4a8e07d"
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "    \n",
        "    initial = tf.random_normal(shape)*0.256\n",
        "    init_image = tf.Variable(initial)\n",
        "    vgg_net = vgg_network(network_weights, init_image)\n",
        "    \n",
        "    original_layers_w = {\"relu4_2\":0.5, \"relu5_2\":0.5}\n",
        "    original_loss = 0\n",
        "    for layer in original_layers:\n",
        "        temp_original_loss = original_layers_w[layer]*original_image_weight *\\\n",
        "            (2*tf.nn.l2_loss(vgg_net[layer]-original_features[layer]))\n",
        "        original_loss += temp_original_loss/original_features[layer].size\n",
        "    style_loss = 0\n",
        "    style_losses = []\n",
        "    for style_layer in style_layers:\n",
        "        layer = vgg_net[style_layer]\n",
        "        feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
        "        size = height * width * channels\n",
        "        features = tf.reshape(layer, (-1, channels))\n",
        "        style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
        "        style_expected = style_features[style_layer]\n",
        "        style_losses.append(style_weights[style_layer] * 2 *\n",
        "                            tf.nn.l2_loss(style_gram_matrix - style_expected) /\n",
        "                            style_expected.size)\n",
        "    style_loss += style_image_weight * tf.reduce_sum(style_losses)\n",
        "    \n",
        "    total_var_x = reduce(mul, init_image[:,1:,:,:].get_shape().as_list(),1)\n",
        "    total_var_y = reduce(mul, init_image[:,:,1:,:].get_shape().as_list(),1)\n",
        "    \n",
        "    first_term = regularization_weight*2\n",
        "    second_term_num = tf.nn.l2_loss(init_image[:,1:, :,:]- init_image[:,:shape[1]-1,:,:])\n",
        "    second_term = second_term_num/total_var_y\n",
        "    third_term_num = tf.nn.l2_loss(init_image[:,:,1:,:]-init_image[:,:,:shape[2]-1,:])\n",
        "    third_term = third_term_num/total_var_x\n",
        "    total_var_loss = first_term*(second_term+third_term)\n",
        "    \n",
        "    loss = original_loss+style_loss+total_var_loss\n",
        "    \n",
        "    optim = tf.train.AdamOptimizer(learning_rate, beta1, beta2)\n",
        "    train_step = optim.minimize(loss)\n",
        "    \n",
        "    with tf.Session() as session:\n",
        "        tf.global_variables_initializer().run()\n",
        "        for i in range(generations):\n",
        "            train_step.run()\n",
        "            \n",
        "            if (i+1)% output_generations==0:\n",
        "                print(\"Iteración {} de {}, loss {}\".format(i+1, generations, session.run(loss)))\n",
        "                image_eval = init_image.eval()\n",
        "                best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
        "                output_file = 'temp_output_{}.jpg'.format(i+1)\n",
        "                imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))\n",
        "        \n",
        "        image_eval = init_image.eval()\n",
        "        best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
        "        output_file = 'final_output.jpg'\n",
        "        imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteración 10 de 100, loss 13755521.0\n",
            "Iteración 20 de 100, loss 11203312.0\n",
            "Iteración 30 de 100, loss 9809610.0\n",
            "Iteración 40 de 100, loss 8884679.0\n",
            "Iteración 50 de 100, loss 8243102.0\n",
            "Iteración 60 de 100, loss 7771988.0\n",
            "Iteración 70 de 100, loss 7416480.0\n",
            "Iteración 80 de 100, loss 7145122.5\n",
            "Iteración 90 de 100, loss 7279878.0\n",
            "Iteración 100 de 100, loss 7467877.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZzwdXp4PRwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}