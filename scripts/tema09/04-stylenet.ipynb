{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "04-stylenet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INFINITY-RUBER/Curso_Deep_Learning_Con_TernsorFlow_Machine-Learning_e_IA-/blob/master/scripts/tema09/04-stylenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sHuHDL0KTlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWvOGvX6K9gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIL6PIxWKPKn",
        "colab_type": "text"
      },
      "source": [
        "# Stylenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJfom7C1KPKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "from operator import mul\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkC4svRQLEye",
        "colab_type": "code",
        "outputId": "60bfd32e-2cbd-4a32-e268-67f485862f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C73uBvFsKPKy",
        "colab_type": "text"
      },
      "source": [
        "Ficheros de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPgrVjr33Cy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r temp_output_*.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJK40yelKPK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ops.reset_default_graph()\n",
        "original_image_file = \"original_image.jpg\"\n",
        "style_image_file = \"style_image.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN3A5frpKPK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_path = \"imagenet-vgg-verydeep-19.mat\"\n",
        "original_image_weight = 5.0\n",
        "style_image_weight = 500.0\n",
        "regularization_weight = 100\n",
        "learning_rate = 10\n",
        "generations = 1000\n",
        "output_generations = 100\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTNzY3IKPLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image = imageio.imread(original_image_file)\n",
        "style_image = imageio.imread(style_image_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWLpgIGxKPLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_shape = original_image.shape\n",
        "style_image = resize(style_image, target_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlgMF7IfKPLT",
        "colab_type": "text"
      },
      "source": [
        "Redes neuronales del paper VGG19 disponible en [Arxiv.org](https://arxiv.org/pdf/1508.06576.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rZT3ZtwKPLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_layers = ['conv1_1', 'relu1_1',\n",
        "              'conv1_2', 'relu1_2', 'pool1',\n",
        "              'conv2_1', 'relu2_1',\n",
        "              'conv2_2', 'relu2_2', 'pool2',\n",
        "              'conv3_1', 'relu3_1',\n",
        "              'conv3_2', 'relu3_2',\n",
        "              'conv3_3', 'relu3_3',\n",
        "              'conv3_4', 'relu3_4', 'pool3',\n",
        "              'conv4_1', 'relu4_1',\n",
        "              'conv4_2', 'relu4_2',\n",
        "              'conv4_3', 'relu4_3',\n",
        "              'conv4_4', 'relu4_4', 'pool4',\n",
        "              'conv5_1', 'relu5_1',\n",
        "              'conv5_2', 'relu5_2',\n",
        "              'conv5_3', 'relu5_3',\n",
        "              'conv5_4', 'relu5_4']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-z6gjzHKPLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_net_info(path_to_mat_file):\n",
        "    vgg_data = scipy.io.loadmat(path_to_mat_file)\n",
        "    normalization_matrix = vgg_data[\"normalization\"][0][0][0]\n",
        "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
        "    network_weights = vgg_data['layers'][0]\n",
        "    return mat_mean, network_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEUAfZVRKPLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_network(network_weights, init_image):\n",
        "    network = {}\n",
        "    image = init_image\n",
        "\n",
        "    for i, layer in enumerate(vgg_layers):\n",
        "        if layer[0] == 'c': #convolución\n",
        "            weights, bias = network_weights[i][0][0][0][0]\n",
        "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
        "            bias = bias.reshape(-1)\n",
        "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
        "            image = tf.nn.bias_add(conv_layer, bias)\n",
        "        elif layer[0] == 'r': #relu\n",
        "            image = tf.nn.relu(image)\n",
        "        else:  #max pooling\n",
        "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
        "        network[layer] = image\n",
        "    return network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HInB1SJxKPLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_layers = ['relu4_2', 'relu5_2']\n",
        "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3xwaapKPLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get network parameters\n",
        "normalization_mean, network_weights = extract_net_info(vgg_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqDKjZwFKPL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape = (1,) + original_image.shape\n",
        "style_shape = (1,) + style_image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz_y4RkCKPL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_features = {}\n",
        "style_features = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a92d2nibKPMD",
        "colab_type": "code",
        "outputId": "80237db2-4cf1-4a45-96a2-2e7f3c21dd07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "style_weights = {l: 1./(len(style_layers)) for l in style_layers}\n",
        "style_weights"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'relu1_1': 0.2,\n",
              " 'relu2_1': 0.2,\n",
              " 'relu3_1': 0.2,\n",
              " 'relu4_1': 0.2,\n",
              " 'relu5_1': 0.2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP_BL93VKPMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_original = tf.Graph()\n",
        "with g_original.as_default(), tf.Session() as session1:\n",
        "    image = tf.placeholder(\"float\", shape=shape)\n",
        "    vgg_net = vgg_network(network_weights, image)\n",
        "    original_minus_mean = original_image - normalization_mean\n",
        "    original_norm = np.array([original_minus_mean])\n",
        "    for layer in original_layers:\n",
        "        original_features[layer] = vgg_net[layer].eval(feed_dict={image:original_norm})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQlbcW4OKPMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_style = tf.Graph()\n",
        "with g_style.as_default(), tf.Session() as session2:\n",
        "    image = tf.placeholder(\"float\", shape=style_shape)\n",
        "    vgg_net = vgg_network(network_weights, image)\n",
        "    style_minus_mean = style_image - normalization_mean\n",
        "    style_norm = np.array([style_minus_mean])\n",
        "    for layer in style_layers:\n",
        "        features = vgg_net[layer].eval(feed_dict={image:style_norm})\n",
        "        features = np.reshape(features, (-1, features.shape[3]))\n",
        "        gram = np.matmul(features.T, features)/features.size\n",
        "        style_features[layer] = gram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvXtmy5Wj3fd",
        "colab_type": "text"
      },
      "source": [
        "### Generarar la modificacion de la imagen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTW3srAEKPMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelo_final():\n",
        "  with tf.Graph().as_default():\n",
        "    \n",
        "    initial = tf.random_normal(shape)*0.256\n",
        "    init_image = tf.Variable(initial)\n",
        "    vgg_net = vgg_network(network_weights, init_image)\n",
        "    \n",
        "    original_layers_w = {\"relu4_2\":0.5, \"relu5_2\":0.5}\n",
        "    original_loss = 0\n",
        "    for layer in original_layers:\n",
        "        temp_original_loss = original_layers_w[layer]*original_image_weight *\\\n",
        "            (2*tf.nn.l2_loss(vgg_net[layer]-original_features[layer]))\n",
        "        original_loss += temp_original_loss/original_features[layer].size\n",
        "    style_loss = 0\n",
        "    style_losses = []\n",
        "    for style_layer in style_layers:\n",
        "        layer = vgg_net[style_layer]\n",
        "        feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
        "        size = height * width * channels\n",
        "        features = tf.reshape(layer, (-1, channels))\n",
        "        style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
        "        style_expected = style_features[style_layer]\n",
        "        style_losses.append(style_weights[style_layer] * 2 *\n",
        "                            tf.nn.l2_loss(style_gram_matrix - style_expected) /\n",
        "                            style_expected.size)\n",
        "    style_loss += style_image_weight * tf.reduce_sum(style_losses)\n",
        "    \n",
        "    total_var_x = reduce(mul, init_image[:,1:,:,:].get_shape().as_list(),1)\n",
        "    total_var_y = reduce(mul, init_image[:,:,1:,:].get_shape().as_list(),1)\n",
        "    \n",
        "    first_term = regularization_weight*2\n",
        "    second_term_num = tf.nn.l2_loss(init_image[:,1:, :,:]- init_image[:,:shape[1]-1,:,:])\n",
        "    second_term = second_term_num/total_var_y\n",
        "    third_term_num = tf.nn.l2_loss(init_image[:,:,1:,:]-init_image[:,:,:shape[2]-1,:])\n",
        "    third_term = third_term_num/total_var_x\n",
        "    total_var_loss = first_term*(second_term+third_term)\n",
        "    \n",
        "    loss = original_loss+style_loss+total_var_loss\n",
        "    \n",
        "    optim = tf.train.AdamOptimizer(learning_rate, beta1, beta2)\n",
        "    train_step = optim.minimize(loss)\n",
        "    \n",
        "    with tf.Session() as session:\n",
        "        tf.global_variables_initializer().run()\n",
        "        for i in range(generations):\n",
        "            train_step.run()\n",
        "            \n",
        "            if (i+1)% output_generations==0:\n",
        "                print(\"Iteración {} de {}, loss {}\".format(i+1, generations, session.run(loss)))\n",
        "                image_eval = init_image.eval()\n",
        "                best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
        "                output_file = 'temp_output_{}.jpg'.format(i+1)\n",
        "                imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))\n",
        "        \n",
        "        image_eval = init_image.eval()\n",
        "        best_image_add_mean = image_eval.reshape(shape[1:])+normalization_mean\n",
        "        output_file = 'final_output.jpg'\n",
        "        imageio.imwrite(output_file, best_image_add_mean.astype(np.uint8))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52MTm6UzkgAp",
        "colab_type": "text"
      },
      "source": [
        "# SISTEMA PARA USAR GPU DE GOOGLE COLAB\n",
        "\n",
        "## imprimir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZzwdXp4PRwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7aygmc8lLrD",
        "colab_type": "text"
      },
      "source": [
        "## ver el tiempo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pzgcOpZt0Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzsMd-7llP7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "637dcff1-c7be-41be-f0db-1438a5e85642"
      },
      "source": [
        "import timeit\n",
        "\n",
        "def entrenamiento_cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    print('trabajando')\n",
        "    #modelo.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=2,verbose=1))\n",
        "  return None\n",
        "\n",
        "cpu_time = timeit.timeit('entrenamiento_cpu()', number=1, setup='from __main__ import entrenamiento_cpu')\n",
        "\n",
        "print('tiempo de entrenamiento '+ str(cpu_time)+ ' segundos')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trabajando\n",
            "tiempo de entrenamiento 0.0003107990000899008 segundos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFiYRd6-pgPr",
        "colab_type": "text"
      },
      "source": [
        "## GPU verificacion disponibilidad\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77OkPKzGppgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc63bb0f-77e4-4306-8dad-6692c1cdfb45"
      },
      "source": [
        "nombre_gpu = tf.test.gpu_device_name()\n",
        "if nombre_gpu != '/device:GPU:0':\n",
        "  raise SyntaxError('Gpu no encongrada')\n",
        "print('GPU es : {}'.format(nombre_gpu))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU es : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwiMkvQRr2Yv",
        "colab_type": "text"
      },
      "source": [
        "#Entrenamiento con GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa4pveLsry2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "509207fc-c976-4160-815e-3dc758383838"
      },
      "source": [
        "import timeit\n",
        "\n",
        "def entrenamiento_gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    modelo_final()\n",
        "    print('ejecutado')\n",
        "  return None\n",
        "\n",
        "gpu_time = timeit.timeit('entrenamiento_gpu()', number=1, setup='from __main__ import entrenamiento_gpu')\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteración 100 de 1000, loss 6972318.0\n",
            "Iteración 200 de 1000, loss 7299189.5\n",
            "Iteración 300 de 1000, loss 5740503.5\n",
            "Iteración 400 de 1000, loss 6013201.0\n",
            "Iteración 500 de 1000, loss 5592290.5\n",
            "Iteración 600 de 1000, loss 5536367.5\n",
            "Iteración 700 de 1000, loss 5434729.5\n",
            "Iteración 800 de 1000, loss 5107514.0\n",
            "Iteración 900 de 1000, loss 5031511.0\n",
            "Iteración 1000 de 1000, loss 5011045.5\n",
            "ejecutado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rme7krWuvZV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f3386d5-ce3b-45ba-a561-7a17b18bb354"
      },
      "source": [
        "print('tiempo de entrenamiento '+ str(gpu_time)+ ' segundos')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tiempo de entrenamiento 735.2419078980001 segundos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrMWYUuZxGYY",
        "colab_type": "text"
      },
      "source": [
        "#USO DE TPU\n",
        "\n",
        "Primero configuramos el note book con la divece TPU\n",
        "\n",
        "## configuracion inicial de TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJ6Mjhtx0XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "  print('TPU encontrada  ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR TPU no encontrada')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoaHvZxQ75Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TPU_model():\n",
        "  with tpu_strategy.scope():\n",
        "    #------aqui colocamos nuestro modelo-----------\n",
        "    modelo_final()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcKeeo6gNc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import timeit\n",
        "\n",
        "def entrenamiento_tpu():\n",
        "  TPU_model()\n",
        "  return None\n",
        "\n",
        "tpu_time = timeit.timeit('entrenamiento_tpu()', number=1, setup='from __main__ import entrenamiento_tpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}